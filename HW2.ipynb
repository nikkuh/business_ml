{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ajg1uezArO0K"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "id": "LNFHyPQHrO0M",
    "outputId": "cedc3095-262e-497c-f745-82608f17b22b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Заместитель председателяnправительства РФnСерг...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4896</td>\n",
       "      <td>Матч 1/16 финала Кубка России по футболу был п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4897</td>\n",
       "      <td>Форвард «Авангарда» Томаш Заборский прокоммент...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                                              title\n",
       "0       6  Заместитель председателяnправительства РФnСерг...\n",
       "1    4896  Матч 1/16 финала Кубка России по футболу был п...\n",
       "2    4897  Форвард «Авангарда» Томаш Заборский прокоммент..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_csv(\"articles.csv\")\n",
    "print(news.shape)\n",
    "news.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "B_Wte8vFrO0S",
    "outputId": "ddc48252-adf7-497d-a51d-caf3852ecff1"
   },
   "outputs": [],
   "source": [
    "users = pd.read_csv(\"users_articles.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gC2mYbVorO0T"
   },
   "source": [
    "Итак, нам нужно получить векторные представления пользователей на основе прочитанным ими новостей и самих новостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IOUvCQhMtEbt",
    "outputId": "73f59a79-440c-449b-feb1-1286decdb84e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: razdel in c:\\users\\huawei\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: pymorphy2 in c:\\users\\huawei\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\huawei\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\huawei\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\huawei\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy2) (2.4.417127.4579844)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\huawei\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install razdel pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "r5aEUfAArO0W"
   },
   "outputs": [],
   "source": [
    "# предобработка текстов\n",
    "import re\n",
    "import numpy as np\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from razdel import tokenize  # сегментация русскоязычного текста на токены и предложения https://github.com/natasha/razdel\n",
    "import pymorphy2  # Морфологический анализатор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkL7Aq9owwIz"
   },
   "source": [
    "Не все слова равны, не все слова одинаково работают. К примеру, союзы и предлоги в нашей задачи никак не помогут, поэтому можем их выкидывать. (*Но в задачах оценки стиля, к примеру, такие слова будут очень полезны*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "stfdHK-ivFlT",
    "outputId": "67b60851-de55-4b06-8d35-88742f872dc5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\huawei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bwgnYaT7rO0X",
    "outputId": "25c4a259-cdad-40eb-8c5f-52f46de2577b"
   },
   "outputs": [],
   "source": [
    "stopword_ru = stopwords.words('russian')\n",
    "# print(len(stopword_ru))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3VeXs0NIxTIU",
    "outputId": "3f105968-8de1-47c5-beb0-b322763b8c3b"
   },
   "outputs": [],
   "source": [
    "# stopword_ru[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fw3Nj3qhrO0X",
    "outputId": "f97d5d84-24fb-4f0e-e26b-c9cdc55cfebb"
   },
   "outputs": [],
   "source": [
    "with open('stopwords.txt') as f:\n",
    "    additional_stopwords = [w.strip() for w in f.readlines() if w]\n",
    "    \n",
    "stopword_ru += additional_stopwords\n",
    "# len(stopword_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vZV9fxlbxjQQ",
    "outputId": "f7096f87-9d1e-4766-a790-332caf9db076"
   },
   "outputs": [],
   "source": [
    "# stopword_ru[200:210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hdyTS-yDrO0Y"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''\n",
    "    очистка текста\n",
    "    \n",
    "    на выходе очищеный текст\n",
    "    '''\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = text.strip('\\n').strip('\\r').strip('\\t')\n",
    "    text = re.sub(\"-\\s\\r\\n\\|-\\s\\r\\n|\\r\\n\", '', str(text))\n",
    "\n",
    "    text = re.sub(\"[0-9]|[-—.,:;_%©«»?*!@#№$^•·&()]|[+=]|[[]|[]]|[/]|\", '', text)\n",
    "    text = re.sub(r\"\\r\\n\\t|\\n|\\\\s|\\r\\t|\\\\n\", ' ', text)\n",
    "    text = re.sub(r'[\\xad]|[\\s+]', ' ', text.strip())\n",
    "    text = re.sub('n', ' ', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "cache = {}\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def lemmatization(text):    \n",
    "    '''\n",
    "    лемматизация\n",
    "        [0] если зашел тип не `str` делаем его `str`\n",
    "        [1] токенизация предложения через razdel\n",
    "        [2] проверка есть ли в начале слова '-'\n",
    "        [3] проверка токена с одного символа\n",
    "        [4] проверка есть ли данное слово в кэше\n",
    "        [5] лемматизация слова\n",
    "        [6] проверка на стоп-слова\n",
    "\n",
    "    на выходе лист лемматизированых токенов\n",
    "    '''\n",
    "\n",
    "    # [0]\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    # [1]\n",
    "    tokens = list(tokenize(text))\n",
    "    words = [_.text for _ in tokens]\n",
    "\n",
    "    words_lem = []\n",
    "    for w in words:\n",
    "        if w[0] == '-': # [2]\n",
    "            w = w[1:]\n",
    "        if len(w) > 1: # [3]\n",
    "            if w in cache: # [4]\n",
    "                words_lem.append(cache[w])\n",
    "            else: # [5]\n",
    "                temp_cach = cache[w] = morph.parse(w)[0].normal_form\n",
    "                words_lem.append(temp_cach)\n",
    "    \n",
    "    words_lem_without_stopwords = [i for i in words_lem if not i in stopword_ru] # [6]\n",
    "    \n",
    "    return words_lem_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "3dkl71coyj3S",
    "outputId": "ad89b1fd-6a97-426d-a978-d64b75084b1b"
   },
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "# morph.parse('сбегали')[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C5grR2zdzi-X",
    "outputId": "0c1b1a9d-a519-42ad-bbce-362b3a908a32"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huawei\\AppData\\Local\\Temp\\ipykernel_2696\\4083466619.py:14: FutureWarning: Possible nested set at position 39\n",
      "  text = re.sub(\"[0-9]|[-—.,:;_%©«»?*!@#№$^•·&()]|[+=]|[[]|[]]|[/]|\", '', text)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    заместитель председателя правительства рф серг...\n",
       "1    матч  финала кубка россии по футболу был приос...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news['title'].iloc[:2].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QB2yF4CsrO0Z",
    "outputId": "f461be3a-9392-41da-c074-9c44e17d1e86",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 27000/27000 [00:27<00:00, 966.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 28 s\n",
      "Wall time: 28 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Запускаем очистку текста. Будет долго...\n",
    "news['title'] = news['title'].progress_apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XmkV3EefzYf0",
    "outputId": "efbf13da-205d-4cbb-8adc-4b0e31ff412a"
   },
   "outputs": [],
   "source": [
    "# news['title'].iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Em-afWYY0Ntx",
    "outputId": "9aebc26d-483e-4546-b665-1418e85550c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [заместитель, председатель, правительство, рф,...\n",
       "1    [матч, финал, кубок, россия, футбол, приостано...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news['title'].iloc[:2].apply(lambda x: lemmatization(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ug4Q6n2VrO0b",
    "outputId": "d129529f-784d-46bd-8daa-6f4000dac10d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 27000/27000 [03:53<00:00, 115.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 53s\n",
      "Wall time: 3min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Запускаем лемматизацию текста. Будет очень долго...\n",
    "news['title'] = news['title'].progress_apply(lambda x: lemmatization(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUGOY6a5rO0c"
   },
   "source": [
    "А теперь в 3 строчки обучим нашу модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "TCyJb8-8rO0d"
   },
   "outputs": [],
   "source": [
    "# сформируем список наших текстов\n",
    "texts = list(news['title'].values)\n",
    "\n",
    "# Создадим корпус из списка с текстами\n",
    "common_dictionary = Dictionary(texts)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYRkOOKyrO0e"
   },
   "source": [
    "Что такое common_dictionary и как он выглядит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ozCl_2RI-WVx",
    "outputId": "dc6e43f9-e9b7-4592-e5b2-90866fda9977"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135723"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "LsOVuc1yrO0f",
    "outputId": "b6d22d64-635c-4c0e-f7e9-20717225dd10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'банк'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_dictionary[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "L9PtOWW97xPr"
   },
   "outputs": [],
   "source": [
    "# common_dictionary.id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "liZN1S1D82Zi",
    "outputId": "098a50d1-d940-4cc2-8194-08948e92de12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1036, 1), (6204, 1), (12347, 1), (135723, 1)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_dictionary.doc2bow(['коллега', 'пошел', 'пить', 'чай'], allow_update=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8FQaUKnrO0h"
   },
   "source": [
    "Все просто - это словарь наших слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXPsfhNYrO0i"
   },
   "source": [
    "Запускаем обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "yKtJddFL8UjP"
   },
   "outputs": [],
   "source": [
    "N_topic = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M7vErZgurO0j",
    "outputId": "d80d7a23-e829-4dc4-8484-e306b843da86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 39min 7s\n",
      "Wall time: 35min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Обучаем модель на корпусе\n",
    "lda = LdaModel(common_corpus, num_topics=N_topic, id2word=common_dictionary, passes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "wSqtDjVJrO0j"
   },
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "\n",
    "# Сохраняем модель на диск\n",
    "temp_file = datapath(\"model.lda\")\n",
    "lda.save(temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "HdhE3p_KysTd"
   },
   "outputs": [],
   "source": [
    "# Загружаем обученную модель с диска\n",
    "lda = LdaModel.load(temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P6AZMJMXrO0l",
    "outputId": "f36e473d-9a46-4dc9-b75f-d8e2473e28e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['форвард', 'авангард', 'томаш', 'заборский', 'прокомментировать', 'игра', 'свой', 'команда', 'матч', 'чемпионат', 'кхл', 'против', 'атланта', 'провести', 'плохой', 'матч', 'нижний', 'новгород', 'против', 'торпедо', 'настраиваться', 'первый', 'минута', 'включиться', 'работа', 'сказать', 'заборский', 'получиться', 'забросить', 'быстрый', 'гол', 'задать', 'хороший', 'темп', 'поединок', 'мочь', 'играть', 'ещё', 'хороший', 'сторона', 'пять', 'очко', 'выезд', 'девять', 'это', 'хороший']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(3, 0.18441282),\n",
       " (4, 0.022598917),\n",
       " (15, 0.22566308),\n",
       " (21, 0.020144101),\n",
       " (23, 0.022547606),\n",
       " (27, 0.060572412),\n",
       " (33, 0.31674802),\n",
       " (35, 0.022681735),\n",
       " (36, 0.05869327),\n",
       " (39, 0.049233317)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создаем новый корпус документов, которые раньше не видели\n",
    "other_texts = list(news['title'].iloc[:3])\n",
    "other_corpus = [common_dictionary.doc2bow(text) for text in other_texts]\n",
    "\n",
    "unseen_doc = other_corpus[2]\n",
    "print(other_texts[2])\n",
    "lda[unseen_doc] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wuxhnNakrO0k"
   },
   "source": [
    "Обучили модель. Теперь 2 вопроса:\n",
    "\n",
    "1. как выглядят наши темы\n",
    "2. как получить для документа вектор значений (вероятности принадлежности каждой теме)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0Q0uqACrO0m",
    "outputId": "47c78d3b-4f73-499a-9e05-fe78cc611f0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_0: рак превысить выдать кость саммит малое антонов\n",
      "topic_1: свет студент продолжительность сочи ньюйорк тенденция аналог\n",
      "topic_2: иран снизить конструкция модернизация освобождение ким обязательство\n",
      "topic_3: это мочь который всё весь говорить эксперт\n",
      "topic_4: мозг улица лётчик автобус необычный седьмой грунт\n",
      "topic_5: боевой сила министерство японский бой оборона противник\n",
      "topic_6: человек который исследование работа научный год статья\n",
      "topic_7: тело экипаж объект км скорость метр пилот\n",
      "topic_8: операция карта парка вылет перенести правительственный вылететь\n",
      "topic_9: земля вода китай повышение пациент китайский опубликовать\n",
      "topic_10: дело это новость снижение москва россия сообщить\n",
      "topic_11: год который первый новый время это советский\n",
      "topic_12: солнце берег вуз порт мышь грузия reuters\n",
      "topic_13: суд гражданин закон решение депутат право госдума\n",
      "topic_14: сша американский погибнуть американец северный чёрный корея\n",
      "topic_15: взрыв продукция москва столица московский сезон ночью\n",
      "topic_16: день планета проверка космос обращение воздух ожидаться\n",
      "topic_17: российский россия млрд военный проект новый система\n",
      "topic_18: турция турецкий сектор египет терминал римский fra\n",
      "topic_19: остров проект конкурс ноябрь городской супруг вирус\n",
      "topic_20: ребёнок женщина мужчина свой год журнал семья\n",
      "topic_21: школа следствие эксперимент писать родитель уголовный энергия\n",
      "topic_22: человек произойти район город находиться место данные\n",
      "topic_23: одежда открыться казахстан еда святой нидерланды наука\n",
      "topic_24: свой русский хороший стать который фильм язык\n",
      "topic_25: смерть британский великобритания белоруссия налог завод скончаться\n",
      "topic_26: мероприятие пенсия квартира город пройти фестиваль программа\n",
      "topic_27: это заявить свой украинский сказать который слово\n",
      "topic_28: ракета сила граница удар российский испытание террорист\n",
      "topic_29: европа германия страна польша италия индия испания\n",
      "topic_30: форум кремль содержать ведение уточнять бежать потенциально\n",
      "topic_31: памятник медведь память доходить оплачивать перевезти строго\n",
      "topic_32: станция миссия французский франция виза париж греция\n",
      "topic_33: команда игра ступень матч золото чемпионат игрок\n",
      "topic_34: россия который президент год газ также страна\n",
      "topic_35: украина киев товар народный рада украинец теория\n",
      "topic_36: банк работа комиссия совет глава агентство директор\n",
      "topic_37: компания рубль цена фонд деньга млн сумма\n",
      "topic_38: дом поверхность газета час родственник ru группа\n",
      "topic_39: год рост это тыс млн составить рынок\n"
     ]
    }
   ],
   "source": [
    "x = lda.show_topics(num_topics=N_topic, num_words=7, formatted=False)\n",
    "topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in x]\n",
    "\n",
    "# Печатаем только слова\n",
    "for topic, words in topics_words:\n",
    "    print(f\"topic_{topic}: \" + \" \".join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54-NWqJlrO0m"
   },
   "source": [
    "Очень неплохо - большинство тем вполне можно описать о чем они"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ty7ZrvUirO0n"
   },
   "source": [
    "Давайте напишем функцию, которая будет нам возвращать векторное представление новости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "KprjS5qLrO0o"
   },
   "outputs": [],
   "source": [
    "def get_lda_vector(lda, text):\n",
    "    unseen_doc = common_dictionary.doc2bow(text)\n",
    "    lda_tuple = lda[unseen_doc]\n",
    "\n",
    "    not_null_topics = dict(zip([i[0] for i in lda_tuple], [i[1] for i in lda_tuple]))\n",
    "\n",
    "    output_vector = []\n",
    "    for i in range(N_topic):\n",
    "        if i not in not_null_topics:\n",
    "            output_vector.append(0)\n",
    "        else:\n",
    "            output_vector.append(not_null_topics[i])\n",
    "    return np.array(output_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ior7y34i-Uwo",
    "outputId": "d641e4e4-27a6-4578-fbb9-96085de600f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.01057281, 0.        , 0.06667945, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.02696209, 0.        , 0.12555218, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.02000924, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.06566251, 0.        ,\n",
       "       0.        , 0.66161233, 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lda_vector(lda, news['title'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VbrPcaB6rO0o",
    "outputId": "93b95352-cf92-4849-a9ac-feccb64278a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 13s\n",
      "Wall time: 2min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "topic_matrix = pd.DataFrame([get_lda_vector(lda, text) for text in news['title'].values])\n",
    "topic_matrix.columns = [f'topic_{i}' for i in range(N_topic)]\n",
    "topic_matrix['doc_id'] = news['doc_id'].values\n",
    "topic_matrix = topic_matrix[['doc_id']+[f'topic_{i}' for i in range(N_topic)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "yHXCN3VsrO0s"
   },
   "outputs": [],
   "source": [
    "doc_dict = dict(zip(topic_matrix['doc_id'].values, topic_matrix[[f'topic_{i}' for i in range(N_topic)]].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "x_M9N6AQrO0u"
   },
   "outputs": [],
   "source": [
    "def get_user_embedding(user_articles_list, doc_dict):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    # print(user_vector)\n",
    "    user_vector = np.mean(user_vector, 0)  # можно не среднее\n",
    "    return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "x_M9N6AQrO0u"
   },
   "outputs": [],
   "source": [
    "def get_user_embedding_median(user_articles_list, doc_dict):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    # print(user_vector)\n",
    "    user_vector = np.median(user_vector, 0)  # можно не среднее\n",
    "    return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "x_M9N6AQrO0u"
   },
   "outputs": [],
   "source": [
    "def get_user_embedding_max(user_articles_list, doc_dict):\n",
    "    user_articles_list = eval(user_articles_list)\n",
    "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
    "    # print(user_vector)\n",
    "    user_vector = np.max(user_vector, 0)  # можно не среднее\n",
    "    return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vflnQMlirO0v",
    "outputId": "ba9ffc11-aee7-4a96-c2fe-2284c192760a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.00358976, 0.11085354, 0.0101708 ,\n",
       "       0.00921569, 0.04306472, 0.00468135, 0.        , 0.00520137,\n",
       "       0.13080177, 0.04540992, 0.        , 0.05987561, 0.01832657,\n",
       "       0.        , 0.00189629, 0.10098949, 0.        , 0.        ,\n",
       "       0.03496249, 0.02080615, 0.00996015, 0.        , 0.        ,\n",
       "       0.00259724, 0.02314653, 0.13221316, 0.0133737 , 0.00314877,\n",
       "       0.        , 0.        , 0.00334058, 0.        , 0.11328334,\n",
       "       0.00407024, 0.00660431, 0.        , 0.01734719, 0.05684691])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_articles_list = users['articles'].iloc[33]\n",
    "\n",
    "get_user_embedding(user_articles_list, doc_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим user_embeddings для 3 различных видов embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D4TX-H1trO00",
    "outputId": "711fc0ec-5bf7-48a1-c951-79ac7411bfe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 859 ms\n",
      "Wall time: 882 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_30</th>\n",
       "      <th>topic_31</th>\n",
       "      <th>topic_32</th>\n",
       "      <th>topic_33</th>\n",
       "      <th>topic_34</th>\n",
       "      <th>topic_35</th>\n",
       "      <th>topic_36</th>\n",
       "      <th>topic_37</th>\n",
       "      <th>topic_38</th>\n",
       "      <th>topic_39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u105138</td>\n",
       "      <td>0.011247</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.053419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002416</td>\n",
       "      <td>0.042379</td>\n",
       "      <td>0.004389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008237</td>\n",
       "      <td>0.011963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075149</td>\n",
       "      <td>0.035619</td>\n",
       "      <td>0.020558</td>\n",
       "      <td>0.036703</td>\n",
       "      <td>0.024163</td>\n",
       "      <td>0.037011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u108690</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006324</td>\n",
       "      <td>0.025715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113376</td>\n",
       "      <td>0.030914</td>\n",
       "      <td>0.013963</td>\n",
       "      <td>0.043987</td>\n",
       "      <td>0.011901</td>\n",
       "      <td>0.031017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u108339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074348</td>\n",
       "      <td>0.023745</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.019782</td>\n",
       "      <td>0.008910</td>\n",
       "      <td>0.004725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029176</td>\n",
       "      <td>0.025609</td>\n",
       "      <td>0.009585</td>\n",
       "      <td>0.044540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid   topic_0   topic_1   topic_2   topic_3   topic_4   topic_5  \\\n",
       "0  u105138  0.011247  0.002513  0.005291  0.053419  0.000000  0.002416   \n",
       "1  u108690  0.001781  0.000000  0.000000  0.118837  0.000000  0.006324   \n",
       "2  u108339  0.000000  0.000000  0.000000  0.074348  0.023745  0.002001   \n",
       "\n",
       "    topic_6   topic_7   topic_8  ...  topic_30  topic_31  topic_32  topic_33  \\\n",
       "0  0.042379  0.004389  0.000000  ...       0.0  0.008237  0.011963       0.0   \n",
       "1  0.025715  0.000000  0.000000  ...       0.0  0.000000  0.000000       0.0   \n",
       "2  0.019782  0.008910  0.004725  ...       0.0  0.000000  0.000000       0.0   \n",
       "\n",
       "   topic_34  topic_35  topic_36  topic_37  topic_38  topic_39  \n",
       "0  0.075149  0.035619  0.020558  0.036703  0.024163  0.037011  \n",
       "1  0.113376  0.030914  0.013963  0.043987  0.011901  0.031017  \n",
       "2  0.133661  0.000000  0.029176  0.025609  0.009585  0.044540  \n",
       "\n",
       "[3 rows x 41 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "user_embeddings = pd.DataFrame([i for i in users['articles'].apply(lambda x: get_user_embedding(x, doc_dict))])\n",
    "user_embeddings.columns = [f'topic_{i}' for i in range(N_topic)]\n",
    "user_embeddings['uid'] = users['uid'].values\n",
    "user_embeddings = user_embeddings[['uid']+[f'topic_{i}' for i in range(N_topic)]]\n",
    "user_embeddings.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D4TX-H1trO00",
    "outputId": "711fc0ec-5bf7-48a1-c951-79ac7411bfe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.42 s\n",
      "Wall time: 1.42 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_30</th>\n",
       "      <th>topic_31</th>\n",
       "      <th>topic_32</th>\n",
       "      <th>topic_33</th>\n",
       "      <th>topic_34</th>\n",
       "      <th>topic_35</th>\n",
       "      <th>topic_36</th>\n",
       "      <th>topic_37</th>\n",
       "      <th>topic_38</th>\n",
       "      <th>topic_39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u105138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u108690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107707</td>\n",
       "      <td>0.020314</td>\n",
       "      <td>0.005652</td>\n",
       "      <td>0.027576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u108339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075069</td>\n",
       "      <td>0.013614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007359</td>\n",
       "      <td>0.049775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid  topic_0  topic_1  topic_2   topic_3   topic_4  topic_5   topic_6  \\\n",
       "0  u105138      0.0      0.0      0.0  0.041325  0.000000      0.0  0.031841   \n",
       "1  u108690      0.0      0.0      0.0  0.117806  0.000000      0.0  0.019403   \n",
       "2  u108339      0.0      0.0      0.0  0.075069  0.013614      0.0  0.020514   \n",
       "\n",
       "   topic_7  topic_8  ...  topic_30  topic_31  topic_32  topic_33  topic_34  \\\n",
       "0      0.0      0.0  ...       0.0       0.0       0.0       0.0  0.084627   \n",
       "1      0.0      0.0  ...       0.0       0.0       0.0       0.0  0.107707   \n",
       "2      0.0      0.0  ...       0.0       0.0       0.0       0.0  0.157725   \n",
       "\n",
       "   topic_35  topic_36  topic_37  topic_38  topic_39  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.020314  0.005652  0.027576  0.000000  0.000000  \n",
       "2  0.000000  0.023175  0.000000  0.007359  0.049775  \n",
       "\n",
       "[3 rows x 41 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "user_embeddings_median = pd.DataFrame([i for i in users['articles'].apply(lambda x: get_user_embedding_median(x, doc_dict))])\n",
    "user_embeddings_median.columns = [f'topic_{i}' for i in range(N_topic)]\n",
    "user_embeddings_median['uid'] = users['uid'].values\n",
    "user_embeddings_median = user_embeddings_median[['uid']+[f'topic_{i}' for i in range(N_topic)]]\n",
    "user_embeddings_median.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D4TX-H1trO00",
    "outputId": "711fc0ec-5bf7-48a1-c951-79ac7411bfe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 797 ms\n",
      "Wall time: 800 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_30</th>\n",
       "      <th>topic_31</th>\n",
       "      <th>topic_32</th>\n",
       "      <th>topic_33</th>\n",
       "      <th>topic_34</th>\n",
       "      <th>topic_35</th>\n",
       "      <th>topic_36</th>\n",
       "      <th>topic_37</th>\n",
       "      <th>topic_38</th>\n",
       "      <th>topic_39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u105138</td>\n",
       "      <td>0.067480</td>\n",
       "      <td>0.015079</td>\n",
       "      <td>0.031747</td>\n",
       "      <td>0.134250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014498</td>\n",
       "      <td>0.112659</td>\n",
       "      <td>0.026332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049421</td>\n",
       "      <td>0.041594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.145774</td>\n",
       "      <td>0.190811</td>\n",
       "      <td>0.101995</td>\n",
       "      <td>0.128946</td>\n",
       "      <td>0.097664</td>\n",
       "      <td>0.181435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u108690</td>\n",
       "      <td>0.010689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025611</td>\n",
       "      <td>0.071247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.204929</td>\n",
       "      <td>0.079595</td>\n",
       "      <td>0.048909</td>\n",
       "      <td>0.155018</td>\n",
       "      <td>0.071403</td>\n",
       "      <td>0.186105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u108339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079756</td>\n",
       "      <td>0.079375</td>\n",
       "      <td>0.012007</td>\n",
       "      <td>0.044887</td>\n",
       "      <td>0.053459</td>\n",
       "      <td>0.028347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.238843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068948</td>\n",
       "      <td>0.126861</td>\n",
       "      <td>0.027885</td>\n",
       "      <td>0.089825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid   topic_0   topic_1   topic_2   topic_3   topic_4   topic_5  \\\n",
       "0  u105138  0.067480  0.015079  0.031747  0.134250  0.000000  0.014498   \n",
       "1  u108690  0.010689  0.000000  0.000000  0.183391  0.000000  0.025611   \n",
       "2  u108339  0.000000  0.000000  0.000000  0.079756  0.079375  0.012007   \n",
       "\n",
       "    topic_6   topic_7   topic_8  ...  topic_30  topic_31  topic_32  topic_33  \\\n",
       "0  0.112659  0.026332  0.000000  ...       0.0  0.049421  0.041594       0.0   \n",
       "1  0.071247  0.000000  0.000000  ...       0.0  0.000000  0.000000       0.0   \n",
       "2  0.044887  0.053459  0.028347  ...       0.0  0.000000  0.000000       0.0   \n",
       "\n",
       "   topic_34  topic_35  topic_36  topic_37  topic_38  topic_39  \n",
       "0  0.145774  0.190811  0.101995  0.128946  0.097664  0.181435  \n",
       "1  0.204929  0.079595  0.048909  0.155018  0.071403  0.186105  \n",
       "2  0.238843  0.000000  0.068948  0.126861  0.027885  0.089825  \n",
       "\n",
       "[3 rows x 41 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "user_embeddings_max = pd.DataFrame([i for i in users['articles'].apply(lambda x: get_user_embedding_max(x, doc_dict))])\n",
    "user_embeddings_max.columns = [f'topic_{i}' for i in range(N_topic)]\n",
    "user_embeddings_max['uid'] = users['uid'].values\n",
    "user_embeddings_max = user_embeddings_max[['uid']+[f'topic_{i}' for i in range(N_topic)]]\n",
    "user_embeddings_max.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "D9jwMilJrO01",
    "outputId": "3420d369-c915-4b9f-f1a1-cd11c782c4d9"
   },
   "outputs": [],
   "source": [
    "target = pd.read_csv(\"users_churn.csv\")\n",
    "# target.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим датасеты, а так же разобьём их на трейн и тест так же в 3 различных вариантах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "8QbVcdI4rO02",
    "outputId": "a4e18e6f-0c9b-4767-9c07-0a54200ee6b4"
   },
   "outputs": [],
   "source": [
    "X = pd.merge(user_embeddings, target, 'left')\n",
    "X_median = pd.merge(user_embeddings_median, target, 'left')\n",
    "X_max = pd.merge(user_embeddings_max, target, 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "U6c1-0YIrO02"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "aKNKOn9srO03"
   },
   "outputs": [],
   "source": [
    "# разделим данные на train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[[f'topic_{i}' for i in range(N_topic)]], \n",
    "                                                    X['churn'], random_state=0)\n",
    "\n",
    "\n",
    "X_train_median, X_test_median, y_train, y_test = train_test_split(X_median[[f'topic_{i}' for i in range(N_topic)]], \n",
    "                                                    X['churn'], random_state=0)\n",
    "\n",
    "\n",
    "X_train_max, X_test_max, y_train, y_test = train_test_split(X_max[[f'topic_{i}' for i in range(N_topic)]], \n",
    "                                                    X['churn'], random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем 3 различные модели логистической регрессии и делаем предсказание вероятностей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8TujsSGprO04",
    "outputId": "2d779846-19e3-45e0-f553-96bea87428bd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg_median = LogisticRegression()\n",
    "logreg_max = LogisticRegression()\n",
    "# обучим \n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_median.fit(X_train_median, y_train)\n",
    "logreg_max.fit(X_train_max, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cB9Y-S0mrO06",
    "outputId": "dbfc0fd4-9020-4c59-fb3c-7a37576daf2a"
   },
   "outputs": [],
   "source": [
    "# наши прогнозы для тестовой выборки\n",
    "preds = logreg.predict_proba(X_test)[:, 1]\n",
    "preds_median = logreg_median.predict_proba(X_test_median)[:, 1]\n",
    "preds_max = logreg_max.predict_proba(X_test_max)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZ9S0UIGrO0-"
   },
   "source": [
    "Рассчитаем Precision, Recall, F_score, Roc_auc_score для всех трёх случаев использования разлиичных методов embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "29MnGc_B5bTY"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import (f1_score, roc_auc_score, precision_score,\n",
    "                             classification_report, precision_recall_curve, confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В этом списке сформируем необходимый набор данных для итоговой таблицы метрик по различным моделям\n",
    "metrics_matrix = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nOw4lCrhrO0_",
    "outputId": "dd8c126a-eeaf-43af-9f7c-d1b1c96c108d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.25658121473498224, F-Score=0.772, Precision=0.722, Recall=0.829\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, preds)\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "print(f'Best Threshold={thresholds[ix]}, F-Score={fscore[ix]:.3f}, Precision={precision[ix]:.3f}, Recall={recall[ix]:.3f}')\n",
    "metrics_matrix.append(['mean', precision[ix], recall[ix], fscore[ix], roc_auc_score(y_test, preds_max)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nOw4lCrhrO0_",
    "outputId": "dd8c126a-eeaf-43af-9f7c-d1b1c96c108d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.26424804602287816, F-Score=0.797, Precision=0.778, Recall=0.816\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, preds_median)\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "print(f'Best Threshold={thresholds[ix]}, F-Score={fscore[ix]:.3f}, Precision={precision[ix]:.3f}, Recall={recall[ix]:.3f}')\n",
    "metrics_matrix.append(['median', precision[ix], recall[ix], fscore[ix], roc_auc_score(y_test, preds_median)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nOw4lCrhrO0_",
    "outputId": "dd8c126a-eeaf-43af-9f7c-d1b1c96c108d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.36998637959286085, F-Score=0.841, Precision=0.850, Recall=0.833\n"
     ]
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, preds_max)\n",
    "fscore = (2 * precision * recall) / (precision + recall)\n",
    "# locate the index of the largest f score\n",
    "ix = np.argmax(fscore)\n",
    "print(f'Best Threshold={thresholds[ix]}, F-Score={fscore[ix]:.3f}, Precision={precision[ix]:.3f}, Recall={recall[ix]:.3f}')\n",
    "metrics_matrix.append(['max', precision[ix], recall[ix], fscore[ix], roc_auc_score(y_test, preds_max)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['mean',\n",
       "  0.7224199288256228,\n",
       "  0.8285714285714286,\n",
       "  0.7718631178707225,\n",
       "  0.9826106168963312],\n",
       " ['median',\n",
       "  0.7782101167315175,\n",
       "  0.8163265306122449,\n",
       "  0.7968127490039841,\n",
       "  0.979080179080179],\n",
       " ['max', 0.85, 0.8326530612244898, 0.8412371134020619, 0.9826106168963312]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_table = pd.DataFrame(metrics_matrix, columns=['Embedding method', 'Precision', 'Recall', 'F score', 'Roc Auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embedding method</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F score</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.72242</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.771863</td>\n",
       "      <td>0.982611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>median</td>\n",
       "      <td>0.77821</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.796813</td>\n",
       "      <td>0.979080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max</td>\n",
       "      <td>0.85000</td>\n",
       "      <td>0.832653</td>\n",
       "      <td>0.841237</td>\n",
       "      <td>0.982611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Embedding method  Precision    Recall   F score   Roc Auc\n",
       "0             mean    0.72242  0.828571  0.771863  0.982611\n",
       "1           median    0.77821  0.816327  0.796813  0.979080\n",
       "2              max    0.85000  0.832653  0.841237  0.982611"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Показатели метрик отличались, когда я использовал разные параметры при обучении моделей LDA, которые не вошли в итоговый ноутбук, но обычно лидировали показания с median-методом или max-методом.\n",
    "\n",
    "Как мне кажется, в таком случае наиболее оправданно использования max-метод."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lesson_2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
